# -*- coding: utf-8 -*-
"""intelligentMatch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PD9TAySXeRxM3fEe2lDtWe3itxDv9GfU

**ORB (failed)**
*unable to detect faulty image*
"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

'''# Load the reference design image and the probe image'''
ref_img = cv2.imread('/content/reference.png')
probe_img = cv2.imread('/content/probe/MeshFlowLin.png')

'''# Convert both images to grayscale'''
ref_gray = cv2.cvtColor(ref_img, cv2.COLOR_BGR2GRAY)
probe_gray = cv2.cvtColor(probe_img, cv2.COLOR_BGR2GRAY)

'''# Perform feature matching between the reference and probe images'''
orb = cv2.ORB_create()
ref_kps, ref_des = orb.detectAndCompute(ref_gray, None)
probe_kps, probe_des = orb.detectAndCompute(probe_gray, None)
bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
matches = bf.match(ref_des, probe_des)
matches = sorted(matches, key=lambda x: x.distance)

'''# Set a threshold for the number of good matches'''
min_good_matches = 10

'''# If the number of good matches is above the threshold, the image is not faulty'''
if len(matches) > min_good_matches:
    print('The equipment is not faulty.')

'''# If the number of good matches is below the threshold, the image is faulty'''
else:
    print('The equipment is faulty.')

    # Find the location of the faulty region in the probe image
    good_matches = matches[:min_good_matches]
    ref_pts = np.float32([ref_kps[m.queryIdx].pt for m in good_matches]).reshape(-1,1,2)
    probe_pts = np.float32([probe_kps[m.trainIdx].pt for m in good_matches]).reshape(-1,1,2)
    M, _ = cv2.findHomography(ref_pts, probe_pts, cv2.RANSAC, 5.0)
    h, w = ref_gray.shape
    defect_corners = np.float32([[0,0], [0,h-1], [w-1,h-1], [w-1,0]]).reshape(-1,1,2)
    defect_corners = cv2.perspectiveTransform(defect_corners, M)
    defect_region = cv2.polylines(probe_img, [np.int32(defect_corners)], True, (0,0,255), 3, cv2.LINE_AA)

    # Display the result
    cv2_imshow(defect_region)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

"""**SIFT (failed)**
*unable to detect faulty image*
"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

'''# Load the reference and the test image'''
ref_image = cv2.imread('/content/reference.png')
test_image = cv2.imread('/content/probe/Element_Optimised_Colour_ShapeLin.png')

'''# Convert the images to grayscale'''
ref_gray = cv2.cvtColor(ref_image, cv2.COLOR_BGR2GRAY)
test_gray = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)

'''# Create SIFT detector object'''
sift = cv2.xfeatures2d.SIFT_create()

'''# Detect keypoints and compute descriptors for the reference and test image'''
kp1, des1 = sift.detectAndCompute(ref_gray, None)
kp2, des2 = sift.detectAndCompute(test_gray, None)

'''# Create brute-force matcher object'''
bf = cv2.BFMatcher()

'''# Match descriptors'''
matches = bf.knnMatch(des1, des2, k=2)

'''# Apply ratio test to filter out false matches'''
good_matches = []
for m,n in matches:
    if m.distance < 0.75*n.distance:
        good_matches.append(m)

'''# Draw matches'''
matched_image = cv2.drawMatches(ref_gray, kp1, test_gray, kp2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

'''# If the number of good matches is less than a threshold, the images are considered faulty'''
if len(good_matches) < 50:
    print("Faulty Image")
    # Get the keypoints from the good matches
    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good_matches ]).reshape(-1,1,2)
    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good_matches ]).reshape(-1,1,2)
    # Compute the homography matrix using RANSAC
    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
    # Get the corners of the reference image
    h,w = ref_gray.shape
    ref_corners = np.float32([ [0,0], [0,h-1], [w-1,h-1], [w-1,0] ]).reshape(-1,1,2)
    # Transform the corners using the homography matrix to get the corresponding corners in the test image
    test_corners = cv2.perspectiveTransform(ref_corners, M)
    # Draw a rectangle around the detected region of difference
    test_image = cv2.polylines(test_image,[np.int32(test_corners)],True,(0,0,255),3, cv2.LINE_AA)
    # Show the images
    cv2_imshow(ref_image)
    cv2_imshow(test_image)
    cv2_imshow(matched_image)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
else:
    print("Perfect Image")

"""**Template matching (failed)**
*it spotting some difference even in perfect image*
"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

'''# Load the reference and the test image'''
ref_image = cv2.imread('/content/reference.png')
test_image = cv2.imread('/content/probe/penetration_checkLin.png')

'''# Convert the images to grayscale'''
ref_gray = cv2.cvtColor(ref_image, cv2.COLOR_BGR2GRAY)
test_gray = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)

'''# Get the size of the reference image'''
h, w = ref_gray.shape

'''# Perform template matching'''
res = cv2.matchTemplate(test_gray, ref_gray, cv2.TM_CCOEFF_NORMED)

'''# Set a threshold to filter out weak matches'''
threshold = 0.8
loc = np.where(res >= threshold)

'''# If there are no matches, the images are considered faulty'''
if len(loc[0]) == 0:
    print("Faulty Image")
    # Draw a rectangle around the detected region of difference
    test_image = cv2.rectangle(test_image, (0, 0), (w, h), (0, 0, 255), 3)
    # Show the images
    cv2_imshow(ref_image)
    cv2_imshow(test_image)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
else:
    print("Perfect Image")

"""**Absolute difference**
*detecting perfect image as faulty*
"""

'''#resizing the images'''
import cv2
from google.colab.patches import cv2_imshow

'''# Load the two images'''
image1 = cv2.imread('/content/reference.png')
image2 = cv2.imread('/content/probe/penetration_checkLin.png')

'''# Get the dimensions of the two images'''
height1, width1, _ = image1.shape
height2, width2, _ = image2.shape

'''# If the two images have different sizes, resize them'''
if height1 != height2 or width1 != width2:
    # Compute the target size based on the larger of the two images
    target_height = max(height1, height2)
    target_width = max(width1, width2)

    # Resize the first image
    image1_resized = cv2.resize(image1, (target_width, target_height))

    # Resize the second image
    image2_resized = cv2.resize(image2, (target_width, target_height))

else:
    # The two images have the same size, no need to resize
    image1_resized = image1
    image2_resized = image2

import cv2
import numpy as np

'''# Load the two images that you want to compare'''
img1 = image1_resized 
img2 = image2_resized 

'''# Convert the images to grayscale'''
gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)

'''# Compute the absolute difference between the two images'''
diff = cv2.absdiff(gray1, gray2)

'''# Apply thresholding to convert the difference map to binary'''
thresh = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)[1]

'''# Apply morphological operations to remove noise and fill gaps'''
kernel = np.ones((5,5), np.uint8)
opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)
closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)

'''# Find the contours in the binary image'''
contours, _ = cv2.findContours(closing, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

'''# Draw the contours on the original images to highlight the differences'''
for contour in contours:
    (x, y, w, h) = cv2.boundingRect(contour)
    cv2.rectangle(img1, (x, y), (x + w, y + h), (0, 0, 255), 2)
    cv2.rectangle(img2, (x, y), (x + w, y + h), (0, 0, 255), 2)

'''# Display the images with differences highlighted'''
cv2_imshow(img1)
cv2_imshow(img2)

'''# Check if there are any differences'''
if len(contours) == 0:
    print('Perfect match')
else:
    print('Differences found')

cv2.waitKey(0)
cv2.destroyAllWindows()

"""**structural similarity**
*detecting perfect image as faulty*
"""

import cv2
from skimage.metrics import structural_similarity as ssim
from google.colab.patches import cv2_imshow

'''# Load the reference and the test image'''
ref_image = image1_resized 
test_image = image2_resized 

'''# Convert the images to grayscale'''
ref_gray = cv2.cvtColor(ref_image, cv2.COLOR_BGR2GRAY)
test_gray = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)

'''# Compute the SSIM between the reference and the test image'''
(score, diff) = ssim(ref_gray, test_gray, full=True)

'''# If the SSIM score is close to 1, the images are considered perfect'''
if score >= 0.99:
    print("Perfect Image")
else:
    print("Faulty Image")
    # Normalize the difference image to the range [0, 255]
    diff = (diff * 255).astype("uint8")
    # Threshold the difference image
    thresh = cv2.threshold(diff, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]
    # Find the contours of the thresholded difference image
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    # Draw a rectangle around each contour
    for contour in contours:
        (x, y, w, h) = cv2.boundingRect(contour)
        cv2.rectangle(test_image, (x, y), (x + w, y + h), (0, 0, 255), 3)
    # Show the images
    cv2_imshow(ref_image)
    cv2_imshow(test_image)
    cv2_imshow(diff)
    cv2_imshow(thresh)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

